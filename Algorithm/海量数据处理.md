# 海量数据处理


## TOP N问题

思路: 分治+hash+小顶堆
- 首先把文件分开
- 针对每个文件hash遍历，统计每个词语的频率
- 使用堆进行遍历
- 把堆归并起来

> 小顶堆（min-heap）有个重要的性质——每个结点的值均不大于其左右孩子结点的值，则堆顶元素即为整个堆的最小值。JDK中PriorityQueue实现了数据结构堆，通过指定comparator字段来表示小顶堆或大顶堆，默认为null，表示自然序（natural ordering）。
>
> 小顶堆解决Top K问题的思路：小顶堆维护当前扫描到的最大100个数，其后每一次的扫描到的元素，若大于堆顶，则入堆，然后删除堆顶；依此往复，直至扫描完所有元素。

## 分布式TOP N问题

6. 分布在100台电脑的海量数据，统计前十。

- 各数据只出现在一台机器中

    - 先在独立机器得到前十

        - 若可以放入内存直接堆排序

        - 若不可全放入内存：哈希分块 -> map统计 -> 归总堆排

    - 再将100台计算机的TOP10组合起来堆排序

- 同一元素可同时出现在不同机器中

    - 遍历所有数据，重新hash取模，使同一个元素只出现在单独的一台电脑中，然后采用上面方法先统计每台电脑TOP10再汇总起来

## 快速外排序问题

7. 有10个1G文件，每行都是一个可重复用户query，按query频度排序。

- 顺序读取十个文件并采取哈希，将query写入10个文件中

- 通过hash_map(query, count)统计每个query出现次数，至少2G内存

- 通过得到的hash_map中query和query_count，对query_count排序并将重新输出到文件中，得到已排序好的文件

- 对十个文件进行归并排序（外排序）

## 公共数据问题

8. A,B两个文件各存放50亿url，每个为64Byte，限制内存4G找出公共url。

- 对A和B两个大文件，先通过url % 1000将数据映射到1000个文件中，单个文件大小约320M（我们只需要检查对应小文件A1 V B1......，不对应小文件不会有相同url）

- 通过hash_set统计，把A1的url存储到hash_set中，再遍历对应的B1小文件，检查是否在hash_set中，若存在则写入外存。重复循环处理对应的1000个对。

9. 1000w有重字符串，对字符串去重。

- 先hash分为多个文件

- 逐个文件检查并插入set中

- 多个set取交集

## 内存内TOP N问题

10. 100w个数字找出最大100个。

- 堆排序法

    - 建大根堆，取走堆顶并重建堆，重复100次

- 快排法

    - 使用快速排序划分，若某次枢纽元在后10000时（具体情况具体分析），对后10000数据排序后取前100

## 位图法

11. 在2.5亿数字中找出不重复的整数。

- 使用2-Bit位图法，00表示不存在，01表示出现一次，10表示出现多次，11无意义。这样只需要1G内存。

- 或者hash划分小文件，小文件使用hash_set检查各个元素，得到的。

12. 如何在40亿数字中快速判断是否有某个数？

- 位图法标记某个数字是否存在，check标记数组。
